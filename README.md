# ğŸ“š Semantic Scholar Research Assistant

An academic assistant that helps you fetch, embed, analyze, and visualize scientific papers using Semantic Scholar and OpenAI. Built with Streamlit.

ğŸ‘‰ **Try it live**: [https://datamining-dkm9iake685izsyfddtr3q.streamlit.app/](https://datamining-dkm9iake685izsyfddtr3q.streamlit.app/)

ğŸ’¸ **Note**: There are around **$10 in OpenAI credit** remaining on the API key. This should be sufficient to analyze ~500â€“1000 papers depending on their length.
#### ğŸ” Why use Semantic Scholar API instead of ArXiv or PubMed?

**âœ… Unified Access to Multiple Sources**  
Semantic Scholar aggregates papers from ArXiv, PubMed, Springer, Elsevier, and more â€” saving you the trouble of querying multiple APIs.  
It currently provides access to **over 215 million papers** (as of April 18, 2025).

**ğŸ“Š Enriched Metadata Features**  
Semantic Scholar provides structured metadata, including:
- Citations and references
- Paper influence score
- Fields of study
- Author affiliations
- Open access status
- Optionally fetch full reference lists for each paper

---

## ğŸ” Step-by-Step Workflow

### 1ï¸âƒ£ Search & Fetch (Tab 1)

- Enter a topic (e.g., _â€œcausal inference in medical AIâ€_)
- The app queries the **Semantic Scholar API** to fetch relevant papers
- The results are displayed, and you can:
  - ğŸ§  Extract independent/dependent variables using GPT
  - ğŸ“ Summarize the abstract
---
### 2ï¸âƒ£ Embed with OpenAI (Tab 1)

- When â€œFetch and Embedâ€ is selected:
  - Each paperâ€™s title and abstract are chunked using `RecursiveCharacterTextSplitter`
  - Chunks are embedded using OpenAI's `text-embedding-3-small`
- Chunks are saved to:  
  ğŸ“ `data/vector_store.json`

> âš ï¸ **API Rate Limit**: Semantic Scholar allows 100 requests per 5 minutes.  
> ğŸ“Œ It's best to embed papers **without references first**, then enrich them later.

#### Enrich later via Tab 4:

![image](https://github.com/user-attachments/assets/3693ddda-ac14-417a-a2d7-d6eb8fcb4157)

Tab 4 will:
- Query all stored papers
- Enrich references (if not already present)
- Apply backoff + retry, but stops after 5 failed attempts

---

### 3ï¸âƒ£ Semantic Retrieval (Tab 3)

- Enter a search query (e.g., _â€œcausal inference in medical AIâ€_)
- The app embeds the query and performs **cosine similarity** search over all embedded chunks
- You can:
  - ğŸ§  Extract variables
  - ğŸ“„ Summarize results using GPT

---

### 4ï¸âƒ£ Reference Enrichment (Tab 4)

- Re-fetch full reference metadata from Semantic Scholar
- Results are cached in:  
  ğŸ“ `data/semantic_scholar_cache/`

---

### 5ï¸âƒ£ Citation Graph Visualization (Tab 4)

- A directed graph is built with `networkx` and rendered with `PyVis`
- ğŸ– Nodes are **color-coded by query**
- ğŸª§ Hovering reveals title, year, and metadata

**Central nodes** (papers currently stored and embedded) appear in the middle of the graph:

![image](https://github.com/user-attachments/assets/6be2243f-5ec1-4ec1-bb96-0a35159d61f0)

---
---

## ğŸš€ Features

- ğŸ” **Semantic Scholar Integration** â€” Search for papers by topic
- ğŸ“„ **Chunk & Embed with OpenAI** â€” Embed paper text into OpenAIâ€™s vector space
- ğŸ§  **Variable Extraction & Summarization** â€” Use GPT to analyze retrieved chunks
- ğŸŒ **Citation Graph Network** â€” Visualize references and citations with PyVis
- ğŸ§  **Query-aware vector search** â€” Retrieve relevant chunks using OpenAI cosine similarity

---

## ğŸ›  Installation

1. Clone the repository:

```bash
git clone https://github.com/your-username/semantic-scholar-assistant.git
cd semantic-scholar-assistant
```

2. Install requirements:

```bash
pip install -r requirements.txt
```

3. Add your OpenAI API key to a `.env` file:

```env
OPENAI_API_KEY=your_openai_key_here
```

---

## â–¶ï¸ Run the App

```bash
streamlit run app.py
```

---

## ğŸ“ Project Structure

```text
â”œâ”€â”€ app.py                            # Main Streamlit app
â”œâ”€â”€ fetch_semantic.py                # Semantic Scholar query + embedding
â”œâ”€â”€ enrich_chroma_papers_with_references.py  # Reference enrichment from API
â”œâ”€â”€ embed_papers_openai.py          # Vector store logic using OpenAI
â”œâ”€â”€ rag_extract_variables.py        # GPT-based extraction and summarization
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ vector_store.json            # Embedded chunks
â”‚   â”œâ”€â”€ semantic_scholar_queries/   # Fetched queries
â”‚   â””â”€â”€ semantic_scholar_cache/     # Cached references
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âœ¨ Future Ideas

- Add filters by author, year, venue
- Add a filter to get only publily available papers
- Support ArXiv + PDF upload pipelines
- Highlight highly cited nodes
- run project on docker 
-  external storage of vectors, for example in Azure storage accounts to ensure scalability

---
